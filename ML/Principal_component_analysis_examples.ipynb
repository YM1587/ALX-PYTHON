{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples: Principal component analysis\n",
    " \n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this train, we learn about dimensionality reduction and choosing principal components to explain the highest variance in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this train, you should be able to:\n",
    "\n",
    "* Understand dimensionality reduction.\n",
    "* Understand principal component analysis (PCA) as a method for dimensionality reduction. \n",
    "* Implement PCA in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction\n",
    "\n",
    "A widely encountered problem in machine learning is that of dimensionality. We typically refer to the size or shape of a dataset as an $n$ x $p$ matrix, where each row from 1 to $n$ represents an observation or data point, and each column from 1 to $p$ represents a variable or feature. With each additional feature, the dimensionality of a dataset increases by 1.\n",
    "\n",
    "The problems with increasing or high levels of dimensionality are as follows:\n",
    "\n",
    "- More storage space required for the data;\n",
    "- More computation time required to work with the data; and\n",
    "- More features mean more chance of feature correlation, and hence feature redundancy.\n",
    "\n",
    "The latter point is the basis on which **principal component analysis** is carried out. A feature that is highly correlated with another increases when the other increases (positive correlation) or decreases when the other increases (negative correlation). This is helpful because if multiple features tend to behave in a corresponding manner in the dataset, they can often be replaced by some smaller number of representative feature(s). This helps to lower the feature space within which the data reside, reducing computation time as well as storage capacity requirements.\n",
    "\n",
    "The goal of dimensionality reduction is to **reduce the number of features in a dataset while minimising the amount of data loss**. There are three primary methods by which this can be done:\n",
    "\n",
    "- Principal Component Analysis (PCA)\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "- Generalised Discriminant Analysis (GDA)\n",
    "\n",
    "In this notebook, we will focus on **PCA**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal component analysis\n",
    "\n",
    "The premise of PCA is that data in some higher number of dimensions can be mapped to some lower number of dimensions whilst retaining the maximum amount of variance in the lower dimension. Broadly speaking, the following steps are involved in a PCA:\n",
    "\n",
    "1. Perform feature scaling on data; \n",
    "2. Construct the covariance matrix of the data;\n",
    "3. Compute the eigenvectors of this matrix. The eigenvectors corresponding to the largest eigenvalues are used to reconstruct a maximal fraction of variance of the original data.\n",
    "\n",
    "These are unfamiliar terms, which we encourage you to investigate on your own. The general idea is that we are able to compute a vector within the feature space of the dataset, which points in the direction of the maximum variance found in the data. This vector is known as the principal component, and we say that it _explains_ the most variance.\n",
    "\n",
    "The second principal component is that vector which is orthogonal (mutually perpendicular) to the first principal component, and which again explains the maximum variance in this orthogonal direction. The third principal component is orthogonal to both of the first two and explains the maximum variance in that direction.\n",
    "\n",
    "This continues for each additional principal component until the maximum number of `p` principal components (there cannot be more principal components than there are features). 100% of the variance can only be explained by all `p` of the features, so we expect to lose some data while reducing the number of dimensions. However, because the principal components are orthogonal and ranked in decreasing order of variance explained, we do normally expect that some subset of all the features will explain a significant proportion of the data.\n",
    "\n",
    "Below is an image which summarises the steps involved in PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/Explore-AI/Pictures/blob/master/sketch-pca-diagram.png?raw=true\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "Image(url= \"https://github.com/Explore-AI/Pictures/blob/master/sketch-pca-diagram.png?raw=true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying PCA to real data\n",
    "\n",
    "The dataset we will use is from the US census of 2015. It contains demographic information such as population, proportion of race, gender, income, child poverty, etc, for each county in the US. A county is a geographic area which is larger than a city but smaller than a state. There are over 3000 counties in the dataset, which should provide sufficient information to perform PCA with.\n",
    "\n",
    "Let's start this example by importing all the packages we'll need, then bring in the data and see what it looks like. \n",
    "\n",
    "> Note: You will need to install the `cufflinks` and `plotly` libraries to generate the plots in this section. Check out [this guide](https://github.com/plotly/plotly.py#jupyterlab-support-python-35) for more help.\n",
    "\n",
    "> Also ensure that you are using a `numpy` version < 2, otherwise you might encounter this error: `ValueError: numpy.dtype size changed, may indicate binary incompatibility`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\eugene\\anaconda3\\lib\\site-packages (5.24.1)\n",
      "Collecting cufflinks\n",
      "  Downloading cufflinks-0.17.3.tar.gz (81 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\eugene\\appdata\\roaming\\python\\python313\\site-packages (from plotly) (25.0)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\eugene\\appdata\\roaming\\python\\python313\\site-packages (from cufflinks) (2.3.5)\n",
      "Requirement already satisfied: pandas>=0.19.2 in c:\\users\\eugene\\appdata\\roaming\\python\\python313\\site-packages (from cufflinks) (2.3.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\eugene\\appdata\\roaming\\python\\python313\\site-packages (from cufflinks) (1.17.0)\n",
      "Collecting colorlover>=0.2.1 (from cufflinks)\n",
      "  Downloading colorlover-0.3.0-py3-none-any.whl.metadata (421 bytes)\n",
      "Requirement already satisfied: setuptools>=34.4.1 in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from cufflinks) (80.9.0)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from cufflinks) (8.30.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from cufflinks) (8.1.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\eugene\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=5.3.0->cufflinks) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->cufflinks) (0.2.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (0.2.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.12 in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (3.0.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.3.0->cufflinks) (0.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\eugene\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.19.2->cufflinks) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\eugene\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.19.2->cufflinks) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\eugene\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.19.2->cufflinks) (2025.2)\n",
      "Requirement already satisfied: executing in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from stack-data->ipython>=5.3.0->cufflinks) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from stack-data->ipython>=5.3.0->cufflinks) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\eugene\\anaconda3\\lib\\site-packages (from stack-data->ipython>=5.3.0->cufflinks) (0.2.2)\n",
      "Downloading colorlover-0.3.0-py3-none-any.whl (8.9 kB)\n",
      "Building wheels for collected packages: cufflinks\n",
      "  Building wheel for cufflinks (setup.py): started\n",
      "  Building wheel for cufflinks (setup.py): finished with status 'done'\n",
      "  Created wheel for cufflinks: filename=cufflinks-0.17.3-py3-none-any.whl size=68792 sha256=5ec236cf4b986064c02dc7d7a19f155418c4adae606ae5d2abfa6a7c9aa9ac7f\n",
      "  Stored in directory: c:\\users\\eugene\\appdata\\local\\pip\\cache\\wheels\\13\\bc\\65\\1ac45445dba1052b5e837dc49f5282c8cb2f934ae9e6f62f0e\n",
      "Successfully built cufflinks\n",
      "Installing collected packages: colorlover, cufflinks\n",
      "\n",
      "   -------------------- ------------------- 1/2 [cufflinks]\n",
      "   ---------------------------------------- 2/2 [cufflinks]\n",
      "\n",
      "Successfully installed colorlover-0.3.0 cufflinks-0.17.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'cufflinks' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'cufflinks'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly cufflinks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cufflinks as cf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_theme(style='whitegrid', palette='muted',\n",
    "        rc={'figure.figsize': (15,10)})\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CensusId</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>...</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>55221</td>\n",
       "      <td>26745</td>\n",
       "      <td>28476</td>\n",
       "      <td>2.6</td>\n",
       "      <td>75.8</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>26.5</td>\n",
       "      <td>23986</td>\n",
       "      <td>73.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>195121</td>\n",
       "      <td>95314</td>\n",
       "      <td>99807</td>\n",
       "      <td>4.5</td>\n",
       "      <td>83.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>26.4</td>\n",
       "      <td>85953</td>\n",
       "      <td>81.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>26932</td>\n",
       "      <td>14497</td>\n",
       "      <td>12435</td>\n",
       "      <td>4.6</td>\n",
       "      <td>46.2</td>\n",
       "      <td>46.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>24.1</td>\n",
       "      <td>8597</td>\n",
       "      <td>71.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>22604</td>\n",
       "      <td>12073</td>\n",
       "      <td>10531</td>\n",
       "      <td>2.2</td>\n",
       "      <td>74.5</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>28.8</td>\n",
       "      <td>8294</td>\n",
       "      <td>76.8</td>\n",
       "      <td>16.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Blount</td>\n",
       "      <td>57710</td>\n",
       "      <td>28512</td>\n",
       "      <td>29198</td>\n",
       "      <td>8.6</td>\n",
       "      <td>87.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>34.9</td>\n",
       "      <td>22189</td>\n",
       "      <td>82.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CensusId    State   County  TotalPop    Men  Women  Hispanic  White  Black  \\\n",
       "0      1001  Alabama  Autauga     55221  26745  28476       2.6   75.8   18.5   \n",
       "1      1003  Alabama  Baldwin    195121  95314  99807       4.5   83.1    9.5   \n",
       "2      1005  Alabama  Barbour     26932  14497  12435       4.6   46.2   46.7   \n",
       "3      1007  Alabama     Bibb     22604  12073  10531       2.2   74.5   21.4   \n",
       "4      1009  Alabama   Blount     57710  28512  29198       8.6   87.9    1.5   \n",
       "\n",
       "   Native  ...  Walk  OtherTransp  WorkAtHome  MeanCommute  Employed  \\\n",
       "0     0.4  ...   0.5          1.3         1.8         26.5     23986   \n",
       "1     0.6  ...   1.0          1.4         3.9         26.4     85953   \n",
       "2     0.2  ...   1.8          1.5         1.6         24.1      8597   \n",
       "3     0.4  ...   0.6          1.5         0.7         28.8      8294   \n",
       "4     0.3  ...   0.9          0.4         2.3         34.9     22189   \n",
       "\n",
       "   PrivateWork  PublicWork  SelfEmployed  FamilyWork  Unemployment  \n",
       "0         73.6        20.9           5.5         0.0           7.6  \n",
       "1         81.5        12.3           5.8         0.4           7.5  \n",
       "2         71.8        20.8           7.3         0.1          17.6  \n",
       "3         76.8        16.1           6.7         0.4           8.3  \n",
       "4         82.0        13.5           4.2         0.4           7.7  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/unsupervised_sprint/acs2015_county_data.csv', encoding=\"UTF-8\").dropna()\n",
    "us_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3218, 37)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the first few rows of the data and then seeing the shape above, we note that there are 37 columns. Not all of these columns are numeric and some of them, like `ID`, `State` and `County`, could be considered labels. Labels are not used in an unsupervised learning environment - but perhaps they will be of use to us later in validating the clusters in the next train. For now, let's remove those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create short list of unwanted columns\n",
    "labels = ['CensusId', 'State', 'County']\n",
    "\n",
    "# declare the features to be all columns, less the unwanted ones from above\n",
    "features = [col for col in us_df.columns if col not in labels]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scales of measurement\n",
    "\n",
    "The most important preprocessing step for our data before any dimensionality reduction may take place is **scaling**.\n",
    "\n",
    "Scaling data is vitally important because not all variables are measured on the same scales and/or using the same units. For instance, the age variable will have a range of 0 to approximately 95, with a mean somewhere around 40. Income, however, will be measured over a much larger numeric range, well into the thousands or millions, with a very different mean. Let's take a look at box plots of the first few variables to better understand this measurement discrepancy.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<1.25,>=1.24Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading numpy-1.24.4.tar.gz (10.9 MB)\n",
      "     ---------------------------------------- 0.0/10.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/10.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/10.9 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/10.9 MB 1.9 MB/s eta 0:00:06\n",
      "     ------ --------------------------------- 1.8/10.9 MB 4.5 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 3.7/10.9 MB 6.6 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 3.9/10.9 MB 5.2 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.2/10.9 MB 4.4 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 4.5/10.9 MB 3.8 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 4.7/10.9 MB 3.6 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 5.5/10.9 MB 3.3 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 5.8/10.9 MB 3.1 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 6.3/10.9 MB 3.0 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 6.6/10.9 MB 2.9 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 7.1/10.9 MB 2.9 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 7.3/10.9 MB 2.7 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 7.6/10.9 MB 2.7 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 8.1/10.9 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 8.7/10.9 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.7/10.9 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 8.9/10.9 MB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 8.9/10.9 MB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 8.9/10.9 MB 2.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 10.0/10.9 MB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.7/10.9 MB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.7/10.9 MB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.9/10.9 MB 2.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [32 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \u001b[35m\"C:\\Users\\Eugene\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "      \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "      \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "    File \u001b[35m\"C:\\Users\\Eugene\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "      json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                               \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    File \u001b[35m\"C:\\Users\\Eugene\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m137\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "      backend = _build_backend()\n",
      "    File \u001b[35m\"C:\\Users\\Eugene\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m70\u001b[0m, in \u001b[35m_build_backend\u001b[0m\n",
      "      obj = import_module(mod_path)\n",
      "    File \u001b[35m\"C:\\Users\\Eugene\\anaconda3\\Lib\\importlib\\__init__.py\"\u001b[0m, line \u001b[35m88\u001b[0m, in \u001b[35mimport_module\u001b[0m\n",
      "      return \u001b[31m_bootstrap._gcd_import\u001b[0m\u001b[1;31m(name[level:], package, level)\u001b[0m\n",
      "             \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1387\u001b[0m, in \u001b[35m_gcd_import\u001b[0m\n",
      "    File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1360\u001b[0m, in \u001b[35m_find_and_load\u001b[0m\n",
      "    File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1310\u001b[0m, in \u001b[35m_find_and_load_unlocked\u001b[0m\n",
      "    File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m488\u001b[0m, in \u001b[35m_call_with_frames_removed\u001b[0m\n",
      "    File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1387\u001b[0m, in \u001b[35m_gcd_import\u001b[0m\n",
      "    File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1360\u001b[0m, in \u001b[35m_find_and_load\u001b[0m\n",
      "    File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1331\u001b[0m, in \u001b[35m_find_and_load_unlocked\u001b[0m\n",
      "    File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m935\u001b[0m, in \u001b[35m_load_unlocked\u001b[0m\n",
      "    File \u001b[35m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[35m1026\u001b[0m, in \u001b[35mexec_module\u001b[0m\n",
      "    File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m488\u001b[0m, in \u001b[35m_call_with_frames_removed\u001b[0m\n",
      "    File \u001b[35m\"C:\\Users\\Eugene\\AppData\\Local\\Temp\\pip-build-env-zzvqpw16\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\"\u001b[0m, line \u001b[35m16\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "      import setuptools.version\n",
      "    File \u001b[35m\"C:\\Users\\Eugene\\AppData\\Local\\Temp\\pip-build-env-zzvqpw16\\overlay\\Lib\\site-packages\\setuptools\\version.py\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "      import pkg_resources\n",
      "    File \u001b[35m\"C:\\Users\\Eugene\\AppData\\Local\\Temp\\pip-build-env-zzvqpw16\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\"\u001b[0m, line \u001b[35m2172\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "      register_finder(\u001b[1;31mpkgutil.ImpImporter\u001b[0m, find_on_path)\n",
      "                      \u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[1;35mAttributeError\u001b[0m: \u001b[35mmodule 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\u001b[0m\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"numpy>=1.24,<1.25\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "\n    Invalid value of type 'builtins.str' received for the 'color' property of box.marker\n        Received value: 'rgba(226, 74, 51, np.float64(1.0))'\n\n    The 'color' property is a color and may be specified as:\n      - A hex string (e.g. '#ff0000')\n      - An rgb/rgba string (e.g. 'rgb(255,0,0)')\n      - An hsl/hsla string (e.g. 'hsl(0,100%,50%)')\n      - An hsv/hsva string (e.g. 'hsv(0,100%,100%)')\n      - A named CSS color:\n            aliceblue, antiquewhite, aqua, aquamarine, azure,\n            beige, bisque, black, blanchedalmond, blue,\n            blueviolet, brown, burlywood, cadetblue,\n            chartreuse, chocolate, coral, cornflowerblue,\n            cornsilk, crimson, cyan, darkblue, darkcyan,\n            darkgoldenrod, darkgray, darkgrey, darkgreen,\n            darkkhaki, darkmagenta, darkolivegreen, darkorange,\n            darkorchid, darkred, darksalmon, darkseagreen,\n            darkslateblue, darkslategray, darkslategrey,\n            darkturquoise, darkviolet, deeppink, deepskyblue,\n            dimgray, dimgrey, dodgerblue, firebrick,\n            floralwhite, forestgreen, fuchsia, gainsboro,\n            ghostwhite, gold, goldenrod, gray, grey, green,\n            greenyellow, honeydew, hotpink, indianred, indigo,\n            ivory, khaki, lavender, lavenderblush, lawngreen,\n            lemonchiffon, lightblue, lightcoral, lightcyan,\n            lightgoldenrodyellow, lightgray, lightgrey,\n            lightgreen, lightpink, lightsalmon, lightseagreen,\n            lightskyblue, lightslategray, lightslategrey,\n            lightsteelblue, lightyellow, lime, limegreen,\n            linen, magenta, maroon, mediumaquamarine,\n            mediumblue, mediumorchid, mediumpurple,\n            mediumseagreen, mediumslateblue, mediumspringgreen,\n            mediumturquoise, mediumvioletred, midnightblue,\n            mintcream, mistyrose, moccasin, navajowhite, navy,\n            oldlace, olive, olivedrab, orange, orangered,\n            orchid, palegoldenrod, palegreen, paleturquoise,\n            palevioletred, papayawhip, peachpuff, peru, pink,\n            plum, powderblue, purple, red, rosybrown,\n            royalblue, rebeccapurple, saddlebrown, salmon,\n            sandybrown, seagreen, seashell, sienna, silver,\n            skyblue, slateblue, slategray, slategrey, snow,\n            springgreen, steelblue, tan, teal, thistle, tomato,\n            turquoise, violet, wheat, white, whitesmoke,\n            yellow, yellowgreen",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m cf\u001b[38;5;241m.\u001b[39mset_config_file(offline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, world_readable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# using plotly to plot the boxplot\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m us_df[features]\u001b[38;5;241m.\u001b[39miplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m'\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoxplots of Features (Unscaled)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\cufflinks\\plotlytools.py:911\u001b[0m, in \u001b[0;36m_iplot\u001b[1;34m(self, kind, data, layout, filename, sharing, title, xTitle, yTitle, zTitle, theme, colors, colorscale, fill, width, dash, mode, interpolation, symbol, size, barmode, sortbars, bargap, bargroupgap, bins, histnorm, histfunc, orientation, boxpoints, annotations, keys, bestfit, bestfit_colors, mean, mean_colors, categories, x, y, z, text, gridcolor, zerolinecolor, margin, labels, values, secondary_y, secondary_y_title, subplots, shape, error_x, error_y, error_type, locations, lon, lat, asFrame, asDates, asFigure, asImage, dimensions, asPlot, asUrl, online, **kwargs)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m    910\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m kind\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 911\u001b[0m \t\t__\u001b[38;5;241m=\u001b[39mBox(y\u001b[38;5;241m=\u001b[39mdf[_]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist(),marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(color\u001b[38;5;241m=\u001b[39mclrs[_]),name\u001b[38;5;241m=\u001b[39m_,\n\u001b[0;32m    912\u001b[0m \t\t\t\tline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(width\u001b[38;5;241m=\u001b[39mwidth),boxpoints\u001b[38;5;241m=\u001b[39mboxpoints)\n\u001b[0;32m    913\u001b[0m \t\t\u001b[38;5;66;03m# 114 - Horizontal Box\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \t\t__[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39morientation\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\plotly\\graph_objs\\_box.py:3396\u001b[0m, in \u001b[0;36mBox.__init__\u001b[1;34m(self, arg, alignmentgroup, boxmean, boxpoints, customdata, customdatasrc, dx, dy, fillcolor, hoverinfo, hoverinfosrc, hoverlabel, hoveron, hovertemplate, hovertemplatesrc, hovertext, hovertextsrc, ids, idssrc, jitter, legend, legendgroup, legendgrouptitle, legendrank, legendwidth, line, lowerfence, lowerfencesrc, marker, mean, meansrc, median, mediansrc, meta, metasrc, name, notched, notchspan, notchspansrc, notchwidth, offsetgroup, opacity, orientation, pointpos, q1, q1src, q3, q3src, quartilemethod, sd, sdmultiple, sdsrc, selected, selectedpoints, showlegend, showwhiskers, sizemode, stream, text, textsrc, uid, uirevision, unselected, upperfence, upperfencesrc, visible, whiskerwidth, width, x, x0, xaxis, xcalendar, xhoverformat, xperiod, xperiod0, xperiodalignment, xsrc, y, y0, yaxis, ycalendar, yhoverformat, yperiod, yperiod0, yperiodalignment, ysrc, zorder, **kwargs)\u001b[0m\n\u001b[0;32m   3394\u001b[0m _v \u001b[38;5;241m=\u001b[39m marker \u001b[38;5;28;01mif\u001b[39;00m marker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _v\n\u001b[0;32m   3395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3396\u001b[0m     \u001b[38;5;28mself\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarker\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _v\n\u001b[0;32m   3397\u001b[0m _v \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   3398\u001b[0m _v \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;28;01mif\u001b[39;00m mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _v\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\plotly\\basedatatypes.py:4860\u001b[0m, in \u001b[0;36mBasePlotlyType.__setitem__\u001b[1;34m(self, prop, value)\u001b[0m\n\u001b[0;32m   4858\u001b[0m \u001b[38;5;66;03m# ### Handle compound property ###\u001b[39;00m\n\u001b[0;32m   4859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(validator, CompoundValidator):\n\u001b[1;32m-> 4860\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_compound_prop(prop, value)\n\u001b[0;32m   4862\u001b[0m \u001b[38;5;66;03m# ### Handle compound array property ###\u001b[39;00m\n\u001b[0;32m   4863\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(validator, (CompoundArrayValidator, BaseDataValidator)):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\plotly\\basedatatypes.py:5271\u001b[0m, in \u001b[0;36mBasePlotlyType._set_compound_prop\u001b[1;34m(self, prop, val)\u001b[0m\n\u001b[0;32m   5268\u001b[0m \u001b[38;5;66;03m# Import value\u001b[39;00m\n\u001b[0;32m   5269\u001b[0m \u001b[38;5;66;03m# ------------\u001b[39;00m\n\u001b[0;32m   5270\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_validator(prop)\n\u001b[1;32m-> 5271\u001b[0m val \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mvalidate_coerce(val, skip_invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_invalid)\n\u001b[0;32m   5273\u001b[0m \u001b[38;5;66;03m# Save deep copies of current and new states\u001b[39;00m\n\u001b[0;32m   5274\u001b[0m \u001b[38;5;66;03m# ------------------------------------------\u001b[39;00m\n\u001b[0;32m   5275\u001b[0m curr_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compound_props\u001b[38;5;241m.\u001b[39mget(prop, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\_plotly_utils\\basevalidators.py:2512\u001b[0m, in \u001b[0;36mCompoundValidator.validate_coerce\u001b[1;34m(self, v, skip_invalid, _validate)\u001b[0m\n\u001b[0;32m   2509\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_class()\n\u001b[0;32m   2511\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m-> 2512\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_class(v, skip_invalid\u001b[38;5;241m=\u001b[39mskip_invalid, _validate\u001b[38;5;241m=\u001b[39m_validate)\n\u001b[0;32m   2514\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_class):\n\u001b[0;32m   2515\u001b[0m     \u001b[38;5;66;03m# Copy object\u001b[39;00m\n\u001b[0;32m   2516\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_class(v)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\plotly\\graph_objs\\box\\_marker.py:470\u001b[0m, in \u001b[0;36mMarker.__init__\u001b[1;34m(self, arg, angle, color, line, opacity, outliercolor, size, symbol, **kwargs)\u001b[0m\n\u001b[0;32m    468\u001b[0m _v \u001b[38;5;241m=\u001b[39m color \u001b[38;5;28;01mif\u001b[39;00m color \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _v\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28mself\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _v\n\u001b[0;32m    471\u001b[0m _v \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    472\u001b[0m _v \u001b[38;5;241m=\u001b[39m line \u001b[38;5;28;01mif\u001b[39;00m line \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _v\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\plotly\\basedatatypes.py:4868\u001b[0m, in \u001b[0;36mBasePlotlyType.__setitem__\u001b[1;34m(self, prop, value)\u001b[0m\n\u001b[0;32m   4864\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_array_prop(prop, value)\n\u001b[0;32m   4866\u001b[0m     \u001b[38;5;66;03m# ### Handle simple property ###\u001b[39;00m\n\u001b[0;32m   4867\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4868\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_prop(prop, value)\n\u001b[0;32m   4869\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4870\u001b[0m     \u001b[38;5;66;03m# Make sure properties dict is initialized\u001b[39;00m\n\u001b[0;32m   4871\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_props()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\plotly\\basedatatypes.py:5212\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[1;34m(self, prop, val)\u001b[0m\n\u001b[0;32m   5210\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   5211\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 5212\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m   5214\u001b[0m \u001b[38;5;66;03m# val is None\u001b[39;00m\n\u001b[0;32m   5215\u001b[0m \u001b[38;5;66;03m# -----------\u001b[39;00m\n\u001b[0;32m   5216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5217\u001b[0m     \u001b[38;5;66;03m# Check if we should send null update\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\plotly\\basedatatypes.py:5207\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[1;34m(self, prop, val)\u001b[0m\n\u001b[0;32m   5204\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_validator(prop)\n\u001b[0;32m   5206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 5207\u001b[0m     val \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mvalidate_coerce(val)\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   5209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_invalid:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\_plotly_utils\\basevalidators.py:1411\u001b[0m, in \u001b[0;36mColorValidator.validate_coerce\u001b[1;34m(self, v, should_raise)\u001b[0m\n\u001b[0;32m   1409\u001b[0m     validated_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvc_scalar(v)\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validated_v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m should_raise:\n\u001b[1;32m-> 1411\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraise_invalid_val(v)\n\u001b[0;32m   1413\u001b[0m     v \u001b[38;5;241m=\u001b[39m validated_v\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\_plotly_utils\\basevalidators.py:296\u001b[0m, in \u001b[0;36mBaseValidator.raise_invalid_val\u001b[1;34m(self, v, inds)\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[0;32m    294\u001b[0m                 name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 296\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    297\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;124;03m    Invalid value of type {typ} received for the '{name}' property of {pname}\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;124;03m        Received value: {v}\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03m{valid_clr_desc}\"\"\"\u001b[39;00m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    302\u001b[0m                 name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    303\u001b[0m                 pname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_name,\n\u001b[0;32m    304\u001b[0m                 typ\u001b[38;5;241m=\u001b[39mtype_str(v),\n\u001b[0;32m    305\u001b[0m                 v\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(v),\n\u001b[0;32m    306\u001b[0m                 valid_clr_desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription(),\n\u001b[0;32m    307\u001b[0m             )\n\u001b[0;32m    308\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: \n    Invalid value of type 'builtins.str' received for the 'color' property of box.marker\n        Received value: 'rgba(226, 74, 51, np.float64(1.0))'\n\n    The 'color' property is a color and may be specified as:\n      - A hex string (e.g. '#ff0000')\n      - An rgb/rgba string (e.g. 'rgb(255,0,0)')\n      - An hsl/hsla string (e.g. 'hsl(0,100%,50%)')\n      - An hsv/hsva string (e.g. 'hsv(0,100%,100%)')\n      - A named CSS color:\n            aliceblue, antiquewhite, aqua, aquamarine, azure,\n            beige, bisque, black, blanchedalmond, blue,\n            blueviolet, brown, burlywood, cadetblue,\n            chartreuse, chocolate, coral, cornflowerblue,\n            cornsilk, crimson, cyan, darkblue, darkcyan,\n            darkgoldenrod, darkgray, darkgrey, darkgreen,\n            darkkhaki, darkmagenta, darkolivegreen, darkorange,\n            darkorchid, darkred, darksalmon, darkseagreen,\n            darkslateblue, darkslategray, darkslategrey,\n            darkturquoise, darkviolet, deeppink, deepskyblue,\n            dimgray, dimgrey, dodgerblue, firebrick,\n            floralwhite, forestgreen, fuchsia, gainsboro,\n            ghostwhite, gold, goldenrod, gray, grey, green,\n            greenyellow, honeydew, hotpink, indianred, indigo,\n            ivory, khaki, lavender, lavenderblush, lawngreen,\n            lemonchiffon, lightblue, lightcoral, lightcyan,\n            lightgoldenrodyellow, lightgray, lightgrey,\n            lightgreen, lightpink, lightsalmon, lightseagreen,\n            lightskyblue, lightslategray, lightslategrey,\n            lightsteelblue, lightyellow, lime, limegreen,\n            linen, magenta, maroon, mediumaquamarine,\n            mediumblue, mediumorchid, mediumpurple,\n            mediumseagreen, mediumslateblue, mediumspringgreen,\n            mediumturquoise, mediumvioletred, midnightblue,\n            mintcream, mistyrose, moccasin, navajowhite, navy,\n            oldlace, olive, olivedrab, orange, orangered,\n            orchid, palegoldenrod, palegreen, paleturquoise,\n            palevioletred, papayawhip, peachpuff, peru, pink,\n            plum, powderblue, purple, red, rosybrown,\n            royalblue, rebeccapurple, saddlebrown, salmon,\n            sandybrown, seagreen, seashell, sienna, silver,\n            skyblue, slateblue, slategray, slategrey, snow,\n            springgreen, steelblue, tan, teal, thistle, tomato,\n            turquoise, violet, wheat, white, whitesmoke,\n            yellow, yellowgreen"
     ]
    }
   ],
   "source": [
    "cf.set_config_file(offline=True, world_readable=True)\n",
    "\n",
    "# using plotly to plot the boxplot\n",
    "us_df[features].iplot(kind='box', title=\"Boxplots of Features (Unscaled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot set '__repr__' attribute of immutable type 'numpy.float64'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Force numpy floats to behave like standard python floats for string formatting\u001b[39;00m\n\u001b[0;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39mset_printoptions(legacy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.25\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m----> 5\u001b[0m np\u001b[38;5;241m.\u001b[39mfloat64\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39mfloat32\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Now run your plot\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot set '__repr__' attribute of immutable type 'numpy.float64'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Force numpy floats to behave like standard python floats for string formatting\n",
    "np.set_printoptions(legacy='1.25') \n",
    "np.float64.__repr__ = lambda self: str(self)\n",
    "np.float32.__repr__ = lambda self: str(self)\n",
    "\n",
    "# Now run your plot\n",
    "us_df[features].iplot(kind='box', title=\"Boxplots of Features (Unscaled)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the scales used for percentage-based variables are very different from population-based ones. Let's scale the columns, and plot the boxplots again for the same variables.\n",
    "\n",
    "> Note: If the following cell times out with a warning, check out [this stackoverflow](https://stackoverflow.com/questions/43288550/iopub-data-rate-exceeded-in-jupyter-notebook-when-viewing-image) for more help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# define scaled data frame variable\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m us_df_scaled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/unsupervised_sprint/acs2015_county_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTF-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      3\u001b[0m us_df_scaled[features] \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mscale(us_df_scaled[features])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# plot boxplots using scaled data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# define scaled data frame variable\n",
    "us_df_scaled = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/unsupervised_sprint/acs2015_county_data.csv', encoding=\"UTF-8\").dropna()\n",
    "us_df_scaled[features] = preprocessing.scale(us_df_scaled[features])\n",
    "\n",
    "# plot boxplots using scaled data\n",
    "us_df_scaled[features].iplot(kind='box', title=\"Boxplots of Features (Scaled)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the features now have a mean of zero and a variance of one, but their boxplots remain the same shape.\n",
    "\n",
    "Let's use what we have learned thus far to interpret an important graph. We'll generate a PCA object and fit the features in the scaled data frame to it. We'll then plot a line graph showing the cumulative variance explained versus the increasing number of components. Remember, the only way to retain 100% of the variance is to retain 100% of the components.\n",
    "\n",
    "Conducting PCA using `sklearn` is simple and can be done with just a few lines of code. We first define a PCA object, then fit it to our data and apply the dimensionality reduction. If this was a supervised learning setting and we had a test set, we could simply apply the dimensionality reduction to it using `pca.transform(X_test)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define PCA object\n",
    "pca = PCA()\n",
    "\n",
    "# fit the PCA model to our data and apply the dimensionality reduction \n",
    "prin_comp = pca.fit_transform(us_df_scaled[features])\n",
    "\n",
    "# create a dataframe containing the principal components\n",
    "pca_df = pd.DataFrame(data = prin_comp)\n",
    "\n",
    "pca_df[\"state\"] = us_df[\"State\"]\n",
    "\n",
    "# plot line graph of cumulative variance explained\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a lesson in dimensionality reduction, we'll need to make a compromise: trading variance retained for components kept. Let's set an arbitrary threshold for the desired variance retained of 85% - that is, we want to determine how many principal components will be required to explain 85% of the variance in our dataset. Looking at the graph, it appears roughly 12 components will explain 85% of the data. That is a significant reduction - from 34 features down to 12. Interestingly, it appears that close to 100% of the variance is explained by the first 23 components, itself a significant reduction.\n",
    "\n",
    "Let's check what the actual number of components would be for 85% variance retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_85 = PCA(.85)\n",
    "pca_85.fit_transform(us_df_scaled[features])\n",
    "print(round(pca_85.explained_variance_ratio_.sum()*100, 1),\n",
    "      \"% of variance explained by\",\n",
    "      pca_85.n_components_,\n",
    "      \"components.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, visualising 13 components is not much easier for a human than 34, but the reduction will certainly lower computation time when working with this dataset. Let's take a look at the variance explained by the first few components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this instance, the first component explains 20%, with the 2nd following closely behind at 17% and the 3rd at 13%. Together, the first three components explain 50% of the data, which is quite a significant achievement considering it is less than a tenth of the total number of original components.\n",
    "\n",
    "Let's plot the first two components on a 2D scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=pca_df[0], y=pca_df[1],\n",
    "                     hue=\"state\",\n",
    "                     palette='RdBu',\n",
    "                     data=pca_df,\n",
    "                     legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting our dimensionality reduction to use\n",
    "\n",
    "We have seen that just 13 components of an original 34 can be used to explain 86.6% of the variance in our dataset. Let us now utilise our reduced dataset, consisting of just 13 components, by using it to build a predictive regressor model.\n",
    "\n",
    "We will use the feature named `IncomePerCap` as the response variable (the one that we will try to predict). This feature was used in our initial PCA, so we will have to make some changes to the dataset to ensure it is not included this time.\n",
    "\n",
    "PCA requires features to be scaled, as we mentioned above. But we don't need to scale the response variable which we will use for prediction, as it is not used in PCA. This is good, because leaving the response as it is means any predicted values and associated errors are easier to interpret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude non-features from data\n",
    "reg_data = us_df_scaled[features]\n",
    "\n",
    "# set aside response variable (Unscaled!)\n",
    "reg_response = us_df[\"IncomePerCap\"]\n",
    "\n",
    "# drop response variable\n",
    "reg_data = reg_data.drop(['IncomePerCap'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split the dataset up into train and test using an arbitrary ratio of 80/20 (train/test, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reg_data, reg_response, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply PCA to the training set with the number of components set to 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create PCA object with n_components set to 13\n",
    "pca_reg = PCA(n_components=13)\n",
    "\n",
    "# fit the PCA model to our data and apply the dimensionality reduction \n",
    "X_train = pca_reg.fit_transform(X_train)\n",
    "\n",
    "# confirm the number of components\n",
    "pca_reg.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_reg.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now reduced our dataset of 33 features into just 13 components. Let's continue by applying the same reduction transformation to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pca_reg.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make use of a random forest regression model to do our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, n_jobs=-1, random_state = 101)\n",
    "\n",
    "# train the model on training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use the trained model to make predictions from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the forest's predict method on the test data\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# calculate the absolute errors\n",
    "errors_reg = abs(predictions - y_test)\n",
    "\n",
    "# print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors_reg), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is able to predict `IncomePerCap` values with a mean absolute error of around $1700. Is that good? Well, let's take a look at the median income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_response.agg(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicts IncomePerCap to within\", round((round(np.mean(errors_reg), 2)/reg_response.agg(\"median\"))*100, 1), \"% of its value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median income value is $23,457, which means our model is able to predict to within ~7% of the actual value on average.\n",
    "\n",
    "We have managed to make predictions using our reduced dataset, but we have no benchmark metric with which to compare our results. We'll need to train a similar model using our original dataset and check its prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features and response data from full dataset\n",
    "features = us_df_scaled[features].drop(['IncomePerCap'], axis=1)\n",
    "response = us_df['IncomePerCap']\n",
    "\n",
    "# split original data\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(features, response, test_size=0.2)\n",
    "\n",
    "# instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, n_jobs=-1, random_state = 101)\n",
    "\n",
    "# train the model on training data\n",
    "rf.fit(X_train_orig, y_train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the forest's predict method on the test data\n",
    "predictions = rf.predict(X_test_orig)\n",
    "\n",
    "# calculate the absolute errors\n",
    "errors = abs(predictions - y_test_orig)\n",
    "\n",
    "# print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicts IncomePerCap to within\", round((round(np.mean(errors), 2)/reg_response.agg(\"median\"))*100, 1), \"% of its value.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the entire dataset, in other words, all 33 features, we are only able to predict `IncomePerCap` to within 6% of its actual value, on average!\n",
    "\n",
    "Thus, it seems using dimensionality reduction here was effective - we reduced the number of features from 33 to 13, and the error in prediction only worsened by 1% (from 6% to 7%). You can imagine that this would be very useful with an extremely large dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages and disadvantages of PCA \n",
    "\n",
    "**Advantages**:\n",
    "- Effective at finding optimal representation of a dataset with fewer dimensions\n",
    "- Effective at decreasing redundancy and filtering noise  \n",
    "- Visualisation of datasets with high-dimensionality\n",
    "- Improves performance of algorithm \n",
    "\n",
    "**Disadvantages**:\n",
    "- May result in some loss of information\n",
    "- Variables may become less interpretable after being transformed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You have now learnt what dimensionality reduction means and why one would use it. You have seen how using PCA can be effective in reducing the dimensions and thus the computational complexity when performing regression. Purpose to experiment with the above example to gain a further understanding of PCA and its uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
