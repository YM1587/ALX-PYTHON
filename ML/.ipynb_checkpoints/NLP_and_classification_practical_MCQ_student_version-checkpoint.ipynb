{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224d77bc",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Practical MCQ: NLP and classification\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "In this train, we'll explore and evaluate different machine learning classifiers through various tasks like model fitting, parameter tuning, and performance comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d230d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "\n",
    "- Utilise vectorisation techniques to process textual data.\n",
    "- Implement logistic regression and measure its accuracy.\n",
    "- Determine optimal model parameters using grid search.\n",
    "- Interpret the output of machine learning models using confusion matrices.\n",
    "- Analyse the performance of classifiers with precision-recall metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8863c65d",
   "metadata": {},
   "source": [
    "> ⚠️ Please note that the multiple choices to all questions are not included in this notebook; they are available exclusively on the MCQ webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0b7683",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecec55",
   "metadata": {},
   "source": [
    "What does the `CountVectorizer` output `X` represent in the code snippet below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc759b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample text data\n",
    "data = [\"Machine learning is fascinating.\", \"Natural language processing and machine learning are closely linked.\"]\n",
    "\n",
    "# Initialise the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "X = vectorizer.fit_transform(data)\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ccb80d",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Modify the code below to compute and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ad301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialise the Logistic Regression model\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da9d0dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Initialise the Logistic Regression model\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc9de7",
   "metadata": {},
   "source": [
    "What is the accuracy of the logistic regression model on the test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd508e27",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "What is the value of True Positive (TP) in the confusion matrix generated by the RandomForestClassifier below? Modify the code to print the value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Generate synthetic binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25577a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive (TP): 113\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Generate synthetic binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#  Extract and print True Positive value\n",
    "TP = cm[1, 1]\n",
    "print(\"True Positive (TP):\", TP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93542c5b",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "What is the best value of the parameter 'C' for the SVC according to the grid search? Modify the code to print the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Load a dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Initialize an SVC (Support Vector Classifier) with a linear kernel\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Define parameter range for C (regularization parameter)\n",
    "param_grid = {'C': np.logspace(-3, 3, 7)}\n",
    "\n",
    "# Setup the grid search with cross-validation\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a41522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of C: 0.001\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Load a dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Initialize an SVC (Support Vector Classifier) with a linear kernel\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Define parameter range for C (regularization parameter)\n",
    "param_grid = {'C': np.logspace(-3, 3, 7)}\n",
    "\n",
    "# Setup the grid search with cross-validation\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best value of C\n",
    "best_C = grid_search.best_params_['C']\n",
    "print(\"Best value of C:\", best_C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98217731",
   "metadata": {},
   "source": [
    "## Question 5 \n",
    "\n",
    "Which code snippet can be used to fill in the missing lines of code to train the SVM classifier, predict the test set results, and print the classification report?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ac91d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       115\n",
      "           1       0.89      0.81      0.85       135\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.84      0.85      0.84       250\n",
      "weighted avg       0.85      0.84      0.84       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the SVM classifier with a radial basis function kernel\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "# [Your Code Here] - Line to add for fitting the model\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "# Predict the test set results\n",
    "# [Your Code Here] - Line to add for making predictions\n",
    "y_pred = svm_rbf.predict(X_test)\n",
    "# Generate and print the classification report\n",
    "# [Your Code Here] - Line to add for printing the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e875cb9",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Given the code below, your task is to select the function from the options provided that correctly completes the task by:\n",
    "\n",
    "i) Creating a function that determines which classifier (KNN or Naive Bayes) has a higher F1 score, or if they have equal scores.\n",
    "\n",
    "ii) Printing the name of the classifier along with its F1 score in the format: 'ClassifierName has the higher F1 score of Score' or 'Both classifiers have the same F1 score of Score'.\n",
    "\n",
    "iii) Executing the function.\n",
    "\n",
    "Select the appropriate code snippet from the options below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6953839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN has the higher F1 score of 0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize KNN and Naive Bayes classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train both classifiers on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set results for both classifiers\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Calculate F1 scores for both classifiers\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "f1_nb = f1_score(y_test, y_pred_nb)\n",
    "\n",
    "# [Your Code Here]\n",
    "def print_best_classifier(f1_knn, f1_nb):\n",
    "    if f1_knn > f1_nb:\n",
    "        print(f\"KNN has the higher F1 score of {f1_knn}\")\n",
    "    elif f1_knn < f1_nb:\n",
    "        print(f\"Naive Bayes has the higher F1 score of {f1_nb}\")\n",
    "    else:\n",
    "        print(f\"Both classifiers have the same F1 score of {f1_knn}\")\n",
    "\n",
    "print_best_classifier(f1_knn, f1_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9667f9",
   "metadata": {},
   "source": [
    "## Question  7 \n",
    "\n",
    "Which of the following options will complete the missing code lines to:\n",
    "\n",
    "i) train the MLPClassifier, \n",
    "\n",
    "ii) predict the test set labels,\n",
    "\n",
    "iii) count the number of misclassified samples,\n",
    "\n",
    "iv) call the function to print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b4c48cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eugene\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Generate a two-moon dataset\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialise the MLPClassifier with one hidden layer with 10 neurons\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)\n",
    "\n",
    "# [Your Code Here] - Train the MLPClassifier on the scaled training data\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "# [Your Code Here] - Predict the labels for the scaled test data\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "# [Your Code Here] - Print the number of misclassified samples in the test set\n",
    "print(np.sum(y_test != y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8065ab7",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "Before running the final line of the code in the snippet below to fit the `grid_search` object, you are asked to perform the following tasks directly in the code:\n",
    "\n",
    "1. Modify the `param_grid` to include a new parameter: `'max_features'` with values ranging from 1 to 4.\n",
    "2. Fit the `grid_search` to the training data.\n",
    "3. After fitting, extract and print the best parameter combination and the corresponding cross-validation score.\n",
    "\n",
    "Which of the following options correctly completes these tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba25b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': None, 'max_features': 2, 'min_samples_split': 20}, CV Score: 0.9371541501976285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Setup a basic decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define a parameter grid over which to optimize the decision tree\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 10, 20]\n",
    "}\n",
    "\n",
    "# Setup the GridSearchCV\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5)\n",
    "param_grid['max_features'] = range(1, 5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best Params: {grid_search.best_params_}, CV Score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b112d7e",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "You are fine-tuning a decision tree classifier for a marketing dataset. To prevent overfitting and ensure robust generalisability, you must adjust the depth of the decision tree after its initialisation but before it is fitted with data. Considering the decision tree `dt` has already been initialised with a random state, which of the following is the correct way to modify the tree's maximum depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38372bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;best&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at<br>  each split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. note::<br><br>    The search for a split does not stop until at least one<br>    valid partition of the node samples is found, even if it requires to<br>    effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=class_weight,-dict%2C%20list%20of%20dict%20or%20%22balanced%22%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict, list of dict or \"balanced\", default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If None, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialise decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# [Your Code Here\n",
    "dt.set_params(max_depth=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537192ee",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "Suppose you are analysing the performance of a new email spam detection system using precision and recall. You have already computed these metrics, and you are about to explore their trade-offs to optimise the classifier's threshold. Given the code snippet below, identify the correct function call that would allow you to adjust and visualise the precision-recall trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b858357c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic data for binary classification\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train a RandomForest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_scores = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# [Your Code Here] - Generate precision and recall values for various thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198463ec",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "\n",
    "You are tasked with enhancing the robustness of a logistic regression model by incorporating feature scaling. You're currently working with a dataset that has significantly varying scales among its features, which can affect the model's performance. Below is a preliminary setup for the logistic regression model. Identify the correct sequence of steps to integrate feature scaling into the modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bd4e937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=penalty,-%7B%27l1%27%2C%20%27l2%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
       "            penalty\n",
       "            <span class=\"param-doc-description\">penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'<br><br>Specify the norm of the penalty:<br><br>- `None`: no penalty is added;<br>- `'l2'`: add a L2 penalty term and it is the default choice;<br>- `'l1'`: add a L1 penalty term;<br>- `'elasticnet'`: both L1 and L2 penalty terms are added.<br><br>.. warning::<br>   Some penalties may not work with some solvers. See the parameter<br>   `solver` below, to know the compatibility between the penalty and<br>   solver.<br><br>.. versionadded:: 0.19<br>   l1 penalty with SAGA solver (allowing 'multinomial' + L1)<br><br>.. deprecated:: 1.8<br>   `penalty` was deprecated in version 1.8 and will be removed in 1.10.<br>   Use `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for<br>   `penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for<br>   `'penalty='elasticnet'`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Inverse of regularization strength; must be a positive float.<br>Like in support vector machines, smaller values specify stronger<br>regularization. `C=np.inf` results in unpenalized logistic regression.<br>For a visual example on the effect of tuning the `C` parameter<br>with an L1 penalty, see:<br>:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=l1_ratio,-float%2C%20default%3D0.0\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.0<br><br>The Elastic-Net mixing parameter, with `0 <= l1_ratio <= 1`. Setting<br>`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.<br>Any value between 0 and 1 gives an Elastic-Net penalty of the form<br>`l1_ratio * L1 + (1 - l1_ratio) * L2`.<br><br>.. warning::<br>   Certain values of `l1_ratio`, i.e. some penalties, may not work with some<br>   solvers. See the parameter `solver` below, to know the compatibility between<br>   the penalty and solver.<br><br>.. versionchanged:: 1.8<br>    Default value changed from None to 0.0.<br><br>.. deprecated:: 1.8<br>    `None` is deprecated and will be removed in version 1.10. Always use<br>    `l1_ratio` to specify the penalty type.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=dual,-bool%2C%20default%3DFalse\">\n",
       "            dual\n",
       "            <span class=\"param-doc-description\">dual: bool, default=False<br><br>Dual (constrained) or primal (regularized, see also<br>:ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation<br>is only implemented for l2 penalty with liblinear solver. Prefer `dual=False`<br>when n_samples > n_features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for stopping criteria.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Specifies if a constant (a.k.a. bias or intercept) should be<br>added to the decision function.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=intercept_scaling,-float%2C%20default%3D1\">\n",
       "            intercept_scaling\n",
       "            <span class=\"param-doc-description\">intercept_scaling: float, default=1<br><br>Useful only when the solver `liblinear` is used<br>and `self.fit_intercept` is set to `True`. In this case, `x` becomes<br>`[x, self.intercept_scaling]`,<br>i.e. a \"synthetic\" feature with constant value equal to<br>`intercept_scaling` is appended to the instance vector.<br>The intercept becomes<br>``intercept_scaling * synthetic_feature_weight``.<br><br>.. note::<br>    The synthetic feature weight is subject to L1 or L2<br>    regularization as all other features.<br>    To lessen the effect of regularization on synthetic feature weight<br>    (and therefore on the intercept) `intercept_scaling` has to be increased.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one.<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.<br><br>.. versionadded:: 0.17<br>   *class_weight='balanced'*</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the<br>data. See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver,-%7B%27lbfgs%27%2C%20%27liblinear%27%2C%20%27newton-cg%27%2C%20%27newton-cholesky%27%2C%20%27sag%27%2C%20%27saga%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27lbfgs%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'<br><br>Algorithm to use in the optimization problem. Default is 'lbfgs'.<br>To choose a solver, you might want to consider the following aspects:<br><br>- 'lbfgs' is a good default solver because it works reasonably well for a wide<br>  class of problems.<br>- For :term:`multiclass` problems (`n_classes >= 3`), all solvers except<br>  'liblinear' minimize the full multinomial loss, 'liblinear' will raise an<br>  error.<br>- 'newton-cholesky' is a good choice for<br>  `n_samples` >> `n_features * n_classes`, especially with one-hot encoded<br>  categorical features with rare categories. Be aware that the memory usage<br>  of this solver has a quadratic dependency on `n_features * n_classes`<br>  because it explicitly computes the full Hessian matrix.<br>- For small datasets, 'liblinear' is a good choice, whereas 'sag'<br>  and 'saga' are faster for large ones;<br>- 'liblinear' can only handle binary classification by default. To apply a<br>  one-versus-rest scheme for the multiclass setting one can wrap it with the<br>  :class:`~sklearn.multiclass.OneVsRestClassifier`.<br><br>.. warning::<br>   The choice of the algorithm depends on the penalty chosen (`l1_ratio=0`<br>   for L2-penalty, `l1_ratio=1` for L1-penalty and `0 < l1_ratio < 1` for<br>   Elastic-Net) and on (multinomial) multiclass support:<br><br>   ================= ======================== ======================<br>   solver            l1_ratio                 multinomial multiclass<br>   ================= ======================== ======================<br>   'lbfgs'           l1_ratio=0               yes<br>   'liblinear'       l1_ratio=1 or l1_ratio=0 no<br>   'newton-cg'       l1_ratio=0               yes<br>   'newton-cholesky' l1_ratio=0               yes<br>   'sag'             l1_ratio=0               yes<br>   'saga'            0<=l1_ratio<=1           yes<br>   ================= ======================== ======================<br><br>.. note::<br>   'sag' and 'saga' fast convergence is only guaranteed on features<br>   with approximately the same scale. You can preprocess the data with<br>   a scaler from :mod:`sklearn.preprocessing`.<br><br>.. seealso::<br>   Refer to the :ref:`User Guide <Logistic_regression>` for more<br>   information regarding :class:`LogisticRegression` and more specifically the<br>   :ref:`Table <logistic_regression_solvers>`<br>   summarizing solver/penalty supports.<br><br>.. versionadded:: 0.17<br>   Stochastic Average Gradient (SAG) descent solver. Multinomial support in<br>   version 0.18.<br>.. versionadded:: 0.19<br>   SAGA solver.<br>.. versionchanged:: 0.22<br>   The default solver changed from 'liblinear' to 'lbfgs' in 0.22.<br>.. versionadded:: 1.2<br>   newton-cholesky solver. Multinomial support in version 1.6.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>Maximum number of iterations taken for the solvers to converge.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>For the liblinear and lbfgs solvers set verbose to any positive<br>number for verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>Useless for liblinear solver. See :term:`the Glossary <warm_start>`.<br><br>.. versionadded:: 0.17<br>   *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Does not have any effect.<br><br>.. deprecated:: 1.8<br>   `n_jobs` is deprecated in version 1.8 and will be removed in 1.10.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# [Your Code Here] - Apply feature scaling to the training data\n",
    "scaler = StandardScaler()\n",
    "# [Your Code Here] - Fit the model on the scaled training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# [Your Code Here] - Apply the same scaling to the test data\n",
    "lr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9ab5e",
   "metadata": {},
   "source": [
    "# Question 12\n",
    "\n",
    "You are fine-tuning a support vector machine (SVM) classifier to categorise images based on their content. The dataset consists of various animal images, and you suspect that different kernel functions might yield better classification accuracy. You decide to test which SVM kernel—linear or radial basis function (RBF)—works best for your specific dataset. Below is your initial code setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc8d1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Linear Kernel: 0.9822222222222222\n",
      "Accuracy with RBF Kernel: 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load a dataset of digit images\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize two SVM classifiers, one with a linear kernel and another with an RBF kernel\n",
    "svm_linear = SVC(kernel='linear')\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "# [Your Code Here] - Train both classifiers on the training data\n",
    "svm_linear.fit(X_train, y_train)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "# [Your Code Here] - Predict the test set results with both classifiers\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "y_pred_rbf = svm_rbf.predict(X_test)\n",
    "# [Your Code Here] - Calculate and print the accuracy scores for both classifiers\n",
    "print(\"Accuracy with Linear Kernel:\", accuracy_score(y_test, y_pred_linear))\n",
    "print(\"Accuracy with RBF Kernel:\", accuracy_score(y_test, y_pred_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097f7ae",
   "metadata": {},
   "source": [
    "Which of the following options correctly completes the task of training both SVM classifiers, predicting the test set results, and calculating the accuracy for each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f3dfa",
   "metadata": {},
   "source": [
    "## Question 13 \n",
    "\n",
    "You are currently evaluating two classifiers, K-Nearest Neighbours (KNN) and Naive Bayes, for a project that involves classifying texts into different categories based on their content. To finalise your model selection, you decide to visually compare their performance using a bar chart. Below is the setup for calculating the accuracy of both models on your dataset. Complete the code by adding the necessary lines to plot the accuracies in a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95ed671d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "data = fetch_20newsgroups(subset='all')\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorise text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialise classifiers\n",
    "knn = KNeighborsClassifier()\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Train classifiers\n",
    "knn.fit(X_train_tfidf, y_train)\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "knn_accuracy = accuracy_score(y_test, knn.predict(X_test_tfidf))\n",
    "nb_accuracy = accuracy_score(y_test, nb.predict(X_test_tfidf))\n",
    "\n",
    "# [Your code here] - Plot the accuracies in a bar chart\n",
    "plt.bar(['KNN', 'Naive Bayes'], [knn_accuracy, nb_accuracy])\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Classifier Accuracies')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca8e77",
   "metadata": {},
   "source": [
    "Which snippet of code will correctly plot the accuracies of KNN and Naive Bayes classifiers in a bar chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db7298",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "You are tasked with evaluating a simple binary classification model using a confusion matrix. The dataset involves predicting whether a given email is spam or not. To better understand the model's performance, you plan to extract specific metrics from the confusion matrix, specifically True Positives (TP) and False Positives (FP). Below is your initial code setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a61dd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 113\n",
      "False Positives: 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic binary classification data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# [Your code here] - Extract and print True Positives and False Positives\n",
    "tp = cm[1, 1]\n",
    "fp = cm[0, 1]\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"False Positives:\", fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf3d05",
   "metadata": {},
   "source": [
    "Which snippet of code correctly extracts and prints the True Positives (TP) and False Positives (FP) from the confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54632b17",
   "metadata": {},
   "source": [
    "Which snippet of code correctly completes the setup to create a pipeline including `PolynomialFeatures` and `LogisticRegression`, fits it on the training data, and makes predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3781c44",
   "metadata": {},
   "source": [
    "## Question 15 (Medium)\n",
    "\n",
    "You are refining a logistic regression model to predict customer churn. The dataset includes various customer interaction metrics. To enhance your model, explore how polynomial features can improve prediction accuracy. This approach allows the model to capture complex interactions between variables. \n",
    "\n",
    "Here is your setup: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08305212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic data with 3 total features: 2 informative + 1 redundant\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=3,\n",
    "    n_informative=2,  # 2 informative features\n",
    "    n_redundant=1,    # 1 redundant feature (linear combination of the informative ones)\n",
    "    n_repeated=0,     # no repeated features\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Apply polynomial features (degree 2)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Fit logistic regression on polynomial features\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ae520be-07d9-43f2-ac4a-736d1519b797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.908\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic data with 3 features\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, \n",
    "    n_features=3, \n",
    "    n_informative=3,  # all 3 features are informative\n",
    "    n_redundant=0,    # no redundant features\n",
    "    n_repeated=0,     # no repeated features\n",
    "    n_classes=2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Apply polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Fit Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a2e94",
   "metadata": {},
   "source": [
    "What is the correct procedure to fit a logistic regression model on the training data after transforming it with polynomial features, and how should predictions be made on the test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
