{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples: Binary classification metrics\n",
    " \n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this train, we'll look at how to assess the performance of a logistic regression model using various binary classification metrics such as accuracy, precision, recall, and the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this train, you should be able to:\n",
    "\n",
    "* Understand how to use and interpret the confusion matrix and the classification report to assess the performance of a binary classifier.\n",
    "* Understand the metrics accuracy, precision, recall, and F1 score.\n",
    "* Know how to implement the various binary classification metrics in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building a logistic regression model\n",
    "\n",
    "We need to train a model in order to assess its performance.\n",
    "\n",
    "### 1.1 The dataset\n",
    "\n",
    "Let's use a classic binary classification dataset for this task: the `Wisconsin Breast Cancer` dataset. It consists of **569 observations** with **30 predictors** and a single binary response variable.\n",
    "\n",
    "Each observation is the result of a scan on a mass of breast tissue for the purpose of **diagnosing or dismissing breast cancer** in a patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Suppress cell warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **target variable**, which we will store in the DataFrame `y`, consists of two classes, each referring to the diagnosis of a scan of a mass of breast tissue:\n",
    "\n",
    "- **1**: the mass is benign.\n",
    "- **0**: the mass is malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas DataFrames\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y, columns=['Target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the 30 **predictor variables** – all continuous and all encoded to four significant digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8   \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9   ...     20     21      22      23      24      25      26      27  \\\n",
       "0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       28       29  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0            1            2           3            4    \\\n",
      "0     17.990000    20.570000    19.690000   11.420000    20.290000   \n",
      "1     10.380000    17.770000    21.250000   20.380000    14.340000   \n",
      "2    122.800000   132.900000   130.000000   77.580000   135.100000   \n",
      "3   1001.000000  1326.000000  1203.000000  386.100000  1297.000000   \n",
      "4      0.118400     0.084740     0.109600    0.142500     0.100300   \n",
      "5      0.277600     0.078640     0.159900    0.283900     0.132800   \n",
      "6      0.300100     0.086900     0.197400    0.241400     0.198000   \n",
      "7      0.147100     0.070170     0.127900    0.105200     0.104300   \n",
      "8      0.241900     0.181200     0.206900    0.259700     0.180900   \n",
      "9      0.078710     0.056670     0.059990    0.097440     0.058830   \n",
      "10     1.095000     0.543500     0.745600    0.495600     0.757200   \n",
      "11     0.905300     0.733900     0.786900    1.156000     0.781300   \n",
      "12     8.589000     3.398000     4.585000    3.445000     5.438000   \n",
      "13   153.400000    74.080000    94.030000   27.230000    94.440000   \n",
      "14     0.006399     0.005225     0.006150    0.009110     0.011490   \n",
      "15     0.049040     0.013080     0.040060    0.074580     0.024610   \n",
      "16     0.053730     0.018600     0.038320    0.056610     0.056880   \n",
      "17     0.015870     0.013400     0.020580    0.018670     0.018850   \n",
      "18     0.030030     0.013890     0.022500    0.059630     0.017560   \n",
      "19     0.006193     0.003532     0.004571    0.009208     0.005115   \n",
      "20    25.380000    24.990000    23.570000   14.910000    22.540000   \n",
      "21    17.330000    23.410000    25.530000   26.500000    16.670000   \n",
      "22   184.600000   158.800000   152.500000   98.870000   152.200000   \n",
      "23  2019.000000  1956.000000  1709.000000  567.700000  1575.000000   \n",
      "24     0.162200     0.123800     0.144400    0.209800     0.137400   \n",
      "25     0.665600     0.186600     0.424500    0.866300     0.205000   \n",
      "26     0.711900     0.241600     0.450400    0.686900     0.400000   \n",
      "27     0.265400     0.186000     0.243000    0.257500     0.162500   \n",
      "28     0.460100     0.275000     0.361300    0.663800     0.236400   \n",
      "29     0.118900     0.089020     0.087580    0.173000     0.076780   \n",
      "\n",
      "           5            6           7           8           9    ...  \\\n",
      "0    12.450000    18.250000   13.710000   13.000000   12.460000  ...   \n",
      "1    15.700000    19.980000   20.830000   21.820000   24.040000  ...   \n",
      "2    82.570000   119.600000   90.200000   87.500000   83.970000  ...   \n",
      "3   477.100000  1040.000000  577.900000  519.800000  475.900000  ...   \n",
      "4     0.127800     0.094630    0.118900    0.127300    0.118600  ...   \n",
      "5     0.170000     0.109000    0.164500    0.193200    0.239600  ...   \n",
      "6     0.157800     0.112700    0.093660    0.185900    0.227300  ...   \n",
      "7     0.080890     0.074000    0.059850    0.093530    0.085430  ...   \n",
      "8     0.208700     0.179400    0.219600    0.235000    0.203000  ...   \n",
      "9     0.076130     0.057420    0.074510    0.073890    0.082430  ...   \n",
      "10    0.334500     0.446700    0.583500    0.306300    0.297600  ...   \n",
      "11    0.890200     0.773200    1.377000    1.002000    1.599000  ...   \n",
      "12    2.217000     3.180000    3.856000    2.406000    2.039000  ...   \n",
      "13   27.190000    53.910000   50.960000   24.320000   23.940000  ...   \n",
      "14    0.007510     0.004314    0.008805    0.005731    0.007149  ...   \n",
      "15    0.033450     0.013820    0.030290    0.035020    0.072170  ...   \n",
      "16    0.036720     0.022540    0.024880    0.035530    0.077430  ...   \n",
      "17    0.011370     0.010390    0.014480    0.012260    0.014320  ...   \n",
      "18    0.021650     0.013690    0.014860    0.021430    0.017890  ...   \n",
      "19    0.005082     0.002179    0.005412    0.003749    0.010080  ...   \n",
      "20   15.470000    22.880000   17.060000   15.490000   15.090000  ...   \n",
      "21   23.750000    27.660000   28.140000   30.730000   40.680000  ...   \n",
      "22  103.400000   153.200000  110.600000  106.200000   97.650000  ...   \n",
      "23  741.600000  1606.000000  897.000000  739.300000  711.400000  ...   \n",
      "24    0.179100     0.144200    0.165400    0.170300    0.185300  ...   \n",
      "25    0.524900     0.257600    0.368200    0.540100    1.058000  ...   \n",
      "26    0.535500     0.378400    0.267800    0.539000    1.105000  ...   \n",
      "27    0.174100     0.193200    0.155600    0.206000    0.221000  ...   \n",
      "28    0.398500     0.306300    0.319600    0.437800    0.436600  ...   \n",
      "29    0.124400     0.083680    0.115100    0.107200    0.207500  ...   \n",
      "\n",
      "           559         560         561         562          563          564  \\\n",
      "0    11.510000   14.050000   11.200000   15.220000    20.920000    21.560000   \n",
      "1    23.930000   27.150000   29.370000   30.620000    25.090000    22.390000   \n",
      "2    74.520000   91.380000   70.670000  103.400000   143.000000   142.000000   \n",
      "3   403.500000  600.400000  386.000000  716.900000  1347.000000  1479.000000   \n",
      "4     0.092610    0.099290    0.074490    0.104800     0.109900     0.111000   \n",
      "5     0.102100    0.112600    0.035580    0.208700     0.223600     0.115900   \n",
      "6     0.111200    0.044620    0.000000    0.255000     0.317400     0.243900   \n",
      "7     0.041050    0.043040    0.000000    0.094290     0.147400     0.138900   \n",
      "8     0.138800    0.153700    0.106000    0.212800     0.214900     0.172600   \n",
      "9     0.065700    0.061710    0.055020    0.071520     0.068790     0.056230   \n",
      "10    0.238800    0.364500    0.314100    0.260200     0.962200     1.176000   \n",
      "11    2.904000    1.492000    3.896000    1.205000     1.026000     1.256000   \n",
      "12    1.936000    2.888000    2.041000    2.362000     8.758000     7.673000   \n",
      "13   16.970000   29.840000   22.810000   22.650000   118.800000   158.700000   \n",
      "14    0.008200    0.007256    0.007594    0.004625     0.006399     0.010300   \n",
      "15    0.029820    0.026780    0.008878    0.048440     0.043100     0.028910   \n",
      "16    0.057380    0.020710    0.000000    0.073590     0.078450     0.051980   \n",
      "17    0.012670    0.016260    0.000000    0.016080     0.026240     0.024540   \n",
      "18    0.014880    0.020800    0.019890    0.021370     0.020570     0.011140   \n",
      "19    0.004738    0.005304    0.001773    0.006142     0.006213     0.004239   \n",
      "20   12.480000   15.300000   11.920000   17.520000    24.290000    25.450000   \n",
      "21   37.160000   33.170000   38.300000   42.790000    29.410000    26.400000   \n",
      "22   82.280000  100.200000   75.190000  128.700000   179.100000   166.100000   \n",
      "23  474.200000  706.700000  439.600000  915.000000  1819.000000  2027.000000   \n",
      "24    0.129800    0.124100    0.092670    0.141700     0.140700     0.141000   \n",
      "25    0.251700    0.226400    0.054940    0.791700     0.418600     0.211300   \n",
      "26    0.363000    0.132600    0.000000    1.170000     0.659900     0.410700   \n",
      "27    0.096530    0.104800    0.000000    0.235600     0.254200     0.221600   \n",
      "28    0.211200    0.225000    0.156600    0.408900     0.292900     0.206000   \n",
      "29    0.087320    0.083210    0.059050    0.140900     0.098730     0.071150   \n",
      "\n",
      "            565          566          567         568  \n",
      "0     20.130000    16.600000    20.600000    7.760000  \n",
      "1     28.250000    28.080000    29.330000   24.540000  \n",
      "2    131.200000   108.300000   140.100000   47.920000  \n",
      "3   1261.000000   858.100000  1265.000000  181.000000  \n",
      "4      0.097800     0.084550     0.117800    0.052630  \n",
      "5      0.103400     0.102300     0.277000    0.043620  \n",
      "6      0.144000     0.092510     0.351400    0.000000  \n",
      "7      0.097910     0.053020     0.152000    0.000000  \n",
      "8      0.175200     0.159000     0.239700    0.158700  \n",
      "9      0.055330     0.056480     0.070160    0.058840  \n",
      "10     0.765500     0.456400     0.726000    0.385700  \n",
      "11     2.463000     1.075000     1.595000    1.428000  \n",
      "12     5.203000     3.425000     5.772000    2.548000  \n",
      "13    99.040000    48.550000    86.220000   19.150000  \n",
      "14     0.005769     0.005903     0.006522    0.007189  \n",
      "15     0.024230     0.037310     0.061580    0.004660  \n",
      "16     0.039500     0.047300     0.071170    0.000000  \n",
      "17     0.016780     0.015570     0.016640    0.000000  \n",
      "18     0.018980     0.013180     0.023240    0.026760  \n",
      "19     0.002498     0.003892     0.006185    0.002783  \n",
      "20    23.690000    18.980000    25.740000    9.456000  \n",
      "21    38.250000    34.120000    39.420000   30.370000  \n",
      "22   155.000000   126.700000   184.600000   59.160000  \n",
      "23  1731.000000  1124.000000  1821.000000  268.600000  \n",
      "24     0.116600     0.113900     0.165000    0.089960  \n",
      "25     0.192200     0.309400     0.868100    0.064440  \n",
      "26     0.321500     0.340300     0.938700    0.000000  \n",
      "27     0.162800     0.141800     0.265000    0.000000  \n",
      "28     0.257200     0.221800     0.408700    0.287100  \n",
      "29     0.066370     0.078200     0.124000    0.070390  \n",
      "\n",
      "[30 rows x 569 columns]\n"
     ]
    }
   ],
   "source": [
    "df_X=X.T\n",
    "print(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, let's take a look at the **distribution of observations** between the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Target\n",
       "1    357\n",
       "0    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "\n",
    "plt.title('Class Frequency')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(ticks=[0,1], labels=[0,1])\n",
    "plt.ylim(top=300)\n",
    "\n",
    "plt.show()\n",
    "y['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of the **imbalance** here: there are 357 observations in class 1 and only 212 in class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression model instance\n",
    "lm = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.09215031863280976)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model intercept\n",
    "lm.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.545138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.242320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.602949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.029918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.015655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Coefficient\n",
       "0     0.545138\n",
       "1     0.242320\n",
       "2     0.602949\n",
       "3    -0.029918\n",
       "4    -0.015655"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model coefficients\n",
    "coeff_df = pd.DataFrame(lm.coef_.T,X.columns,columns=['Coefficient'])\n",
    "coeff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "pred_lm = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have made some predictions on the test data. Now, let's compare those predictions to the ground truth labels of the test dataset and determine how well the model has actually performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Assessing model performance using the confusion matrix\n",
    "\n",
    "A confusion matrix, shown below, is a table that describes the performance of a classification model, or classifier, on a set of test data for which the true values are known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/sketch-conf-matrix.png\" alt=\"sketch-conf-matrix\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the related terminology, each referring to a separate cell in the confusion matrix above. Note that they represent whole numbers and not proportions.\n",
    "\n",
    "- **True negatives (TN)**: These are cases in which we predicted a negative result, and the true result is also negative.\n",
    "- **True positives (TP)**: We predicted a positive result and the true result is positive.\n",
    "- **False positives (FP)**: We predicted a positive result, but the true result is negative. Also known as a **Type I error**.\n",
    "- **False negatives (FN)**: We predicted a negative result, but the true result is positive. Also known as a **Type II error**.\n",
    "\n",
    "Take a moment to familiarise yourself with the table and how we arrive at each of the four categories. Use the sketch below to note which prediction falls into which category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/sketch-compare-predictions.png\" alt=\"sketch-compare-predictions\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Confusion matrix in `sklearn`\n",
    "\n",
    "Let's start by importing the `confusion_matrix` object to check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix takes in two arguments: \n",
    "- The unseen test data, `y_test`.\n",
    "- Our predictions, `pred_lm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36,  3],\n",
       "       [ 5, 70]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not easy to read – let's convert it into a DataFrame and add the appropriate labels to make it clear which value is which.\n",
    "\n",
    "The matrix orders the rows and columns in a sorted fashion according to the labels. Our labels are 0 and 1, so the first row/column is 0, and the 2nd row/column is 1. Let's give it the appropriate labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0: Malignant</th>\n",
       "      <th>1: Benign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0: Malignant</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1: Benign</th>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0: Malignant  1: Benign\n",
       "0: Malignant            36          3\n",
       "1: Benign                5         70"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['0: Malignant', '1: Benign']\n",
    "\n",
    "pd.DataFrame(data=confusion_matrix(y_test, pred_lm), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "\n",
    "That looks better. A few notes on the matrix:\n",
    "\n",
    "- Each **row** represents the **ground truth totals** for _Malignant_ and _Benign_. In other words, the sum of all the values in the first row is the total number of observations in our test dataset labelled _Malignant_.\n",
    "\n",
    "- Each **column** represents the **totals for the predictions** in each of _Malignant_ and _Benign_.\n",
    "\n",
    "- The **intersection** of each row/column gives us a different aspect of the results: **TP**, **TN**, **FP**, or **FN**, as described for the table sketched above.\n",
    "\n",
    "> Therefore, based on the confusion matrix shown here, how many observations did the model classify as `Malignant`, and how many were classified as `Benign`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Overall accuracy\n",
    "\n",
    "The results shown above lead us to our first classification metric: **overall accuracy**, which we calculate according to the following formula:\n",
    "\n",
    "$$Accuracy =  \\frac{Correct\\space predictions}{Total\\space predictions} = \\frac{TP + \\space TN}{TP \\space + \\space TN \\space + \\space FP \\space + \\space FN}$$\n",
    "\n",
    "Our overall accuracy is calculated as follows:\n",
    "\n",
    "$$Accuracy =  \\frac{Correct\\space predictions}{Total\\space predictions} = \\frac{70 + 36}{70 + 36 + 3 + 5} = 0.93$$\n",
    "\n",
    "At first glance, this appears to be a useful, catch-all metric which tells us everything we need to know about our model. The problem is that it lacks detail.\n",
    "\n",
    "Consider the following scenario:\n",
    "\n",
    "- We have 100 observations in our test dataset: 90 of them are labelled `No`, the remaining 10 are labelled `Yes`. \n",
    "\n",
    "- At prediction time, our model classifies all 100 observations to be in category `No`. Our model made 100 predictions and got all 90 of the `No` observations correct, giving it an overall accuracy of 90%!\n",
    "\n",
    "- Sounds good right? The problem is that the model got literally none of the `Yes`-labelled observations correct – 0/10! What if the `Yes` cases were for patients who have cancer or a transaction that is fraudulent? Those are important results, and we would have missed all of them.\n",
    "\n",
    "> That highlights the importance of being accurate – not just overall, but in each particular class too.\n",
    "\n",
    "Let's look at a few metrics which are a little more comprehensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Assessing model performance using the classification report\n",
    "\n",
    "The **classification report** gives us more information on where our model is going wrong – looking specifically at the performance caused by **Type I and II errors**.  \n",
    "\n",
    "The following **metrics** are calculated as **part of the classification report**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Precision\n",
    "\n",
    "**Answers:** When it predicts `yes`, how often is it correct? \n",
    "\n",
    "$$ Precision = \\frac{TP}{TP \\space + FP} = \\frac{TP}{Total \\space Predicted \\space Positive} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Recall\n",
    "\n",
    "**Answers:** When the outcome is actually `yes`, how often do we predict it as such?\n",
    "\n",
    "$$ Recall = \\frac{TP}{TP \\space + FN} = \\frac{TP}{Total \\space Actual \\space Positive}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 F1 score\n",
    "\n",
    "**Answers:** What is the weighted average of precision and recall? \n",
    "\n",
    "$$F_1 = 2 \\times \\frac {Precision \\space \\times \\space Recall }{Precision \\space + \\space Recall }$$\n",
    "\n",
    "F1 score might be a better measure to use if we need to **seek a balance** between precision and recall _and_ there is an **uneven class** distribution (large number of 1s vs 0s or vice versa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Classification report in `sklearn`\n",
    "\n",
    "Let's import the `classification_report` object to check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the confusion matrix, the **classification matrix** takes in **two arguments**: the unseen y_test data as well as our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "0: Malignant       0.88      0.92      0.90        39\n",
      "   1: Benign       0.96      0.93      0.95        75\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.92      0.93      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(classification_report(y_test, pred_lm, target_names=['0: Malignant', '1: Benign']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "We now have a far more comprehensive view of the performance of our model.\n",
    "\n",
    "- Clearly, the precision, recall, and F1 score **values for the Benign class are higher**, and this has to do with the class imbalance we referred to earlier in the tutorial. There are more observations with the Benign label, so the model gets **_better_** at classifying those ones because it has more evidence of them.\n",
    "\n",
    "- The corresponding **values in the Malignant class are lower** for the same reason.\n",
    "\n",
    "- The **weighted F1 score** here gives us a good indication using a single value of how well the model is performed. It is somewhere between the accuracies that the model achieved for each of class 0 and 1, but slightly in favour of class 1, of which there were more examples.\n",
    "\n",
    "- Perhaps the most important information in the above table is in the last row, indicating the weighted average.\n",
    "\n",
    "- Unlike the values in the `macro avg` row which are computed using: \n",
    "\n",
    "$$\\frac{class\\_0\\_metric \\quad + \\quad class\\_1\\_metric}{2}$$ \n",
    "\n",
    "- The `weighted avg` values are computed using: \n",
    "\n",
    "$$\\frac{class\\_0\\_metric \\, \\times \\, \\%\\_class\\_0\\_labels  \\quad + \\quad class\\_1\\_metric \\, \\times \\, \\%\\_class\\_1\\_labels}{2}$$ \n",
    "\n",
    "which takes into account the **proportions of each class** fed into the model (as indicated in the `support` column)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this train, we have seen or been introduced to:\n",
    "\n",
    "- Using the confusion matrix to assess the classifications from a binary classifier.\n",
    "- Understanding the four result categories a classification may fall into (TP, TN, etc.).\n",
    "- Four metrics for assessing a classifier: accuracy, precision, recall, and F1 score.\n",
    "- The importance of ensuring good performance in _each class_, as opposed to just overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
